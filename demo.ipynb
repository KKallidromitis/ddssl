{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70b33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from utils import get_dataset, get_network, get_daparam,TensorDataset, epoch, ParamDiffAug\n",
    "from lib.data.kinectics import KinecticsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8312c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments:\n",
    "    pass\n",
    "\n",
    "args = arguments()\n",
    "args.zca = False\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args.dsa_param = ParamDiffAug()\n",
    "args.buffer_path = './buffers'\n",
    "args.dataset = 'kinetics400'\n",
    "args.data_path = '/shared/group/kinetics/'\n",
    "args.batch_real = 10\n",
    "args.subset = 'imagenette'\n",
    "args.model = 'ConvNet'\n",
    "args.batch_train = 10\n",
    "args.num_experts = 100\n",
    "args.lr_teacher = 0.01\n",
    "args.mom = 0\n",
    "args.l2 = 0\n",
    "args.train_epochs = 50\n",
    "args.dsa = True\n",
    "args.dsa_strategy = 'color_crop_cutout_flip_scale_rotate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = (128, 128)\n",
    "mean=[0.43216, 0.394666, 0.37645]\n",
    "std=[0.22803, 0.22145, 0.216989]\n",
    "num_classes=1\n",
    "class_map = {0:1}\n",
    "transform = transforms.Compose([transforms.ToPILImage(),transforms.Normalize(mean=mean, std=std),transforms.Resize(im_size),transforms.CenterCrop(im_size)])\n",
    "dst_train = KinecticsWrapper(args.data_path,split='train_256',frames_per_clip=10)\n",
    "# dst_test = KinecticsWrapper(args.data_path,frames_per_clip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444f8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hyper-parameters: \\n', args.__dict__)\n",
    "\n",
    "save_dir = os.path.join(args.buffer_path, args.dataset)\n",
    "if args.dataset == \"ImageNet\":\n",
    "    save_dir = os.path.join(save_dir, args.subset, str(args.res))\n",
    "if args.dataset in [\"CIFAR10\", \"CIFAR100\"] and not args.zca:\n",
    "    save_dir += \"_NO_ZCA\"\n",
    "save_dir = os.path.join(save_dir, args.model)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' organize the real dataset '''\n",
    "images_all = []\n",
    "labels_all = []\n",
    "indices_class = [[] for c in range(num_classes)]\n",
    "print(\"BUILDING DATASET\")\n",
    "for i in tqdm(range(len(dst_train))):\n",
    "    sample = [j for j in dst_train[i]]\n",
    "    images_all.append(torch.unsqueeze(sample[0], dim=0))\n",
    "    labels_all.append(0)\n",
    "\n",
    "for i, lab in tqdm(enumerate(labels_all)):\n",
    "    indices_class[lab].append(i)\n",
    "images_all = torch.cat(images_all, dim=0).to(\"cpu\")\n",
    "labels_all = torch.tensor(labels_all, dtype=torch.long, device=\"cpu\")\n",
    "\n",
    "for c in range(num_classes):\n",
    "    print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
    "\n",
    "for ch in range(channel):\n",
    "    print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "trajectories = []\n",
    "\n",
    "dst_train = TensorDataset(copy.deepcopy(images_all.detach()), copy.deepcopy(labels_all.detach()))\n",
    "trainloader = torch.utils.data.DataLoader(dst_train, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
    "\n",
    "''' set augmentation for whole-dataset training '''\n",
    "args.dc_aug_param = get_daparam(args.dataset, args.model, args.model, None)\n",
    "args.dc_aug_param['strategy'] = 'crop_scale_rotate'  # for whole-dataset training\n",
    "print('DC augmentation parameters: \\n', args.dc_aug_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a07459",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(0, args.num_experts):\n",
    "\n",
    "    ''' Train synthetic data '''\n",
    "    teacher_net = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
    "    teacher_net.train()\n",
    "    lr = args.lr_teacher\n",
    "    teacher_optim = torch.optim.SGD(teacher_net.parameters(), lr=lr, momentum=args.mom, weight_decay=args.l2)  # optimizer_img for synthetic data\n",
    "    teacher_optim.zero_grad()\n",
    "\n",
    "    timestamps = []\n",
    "\n",
    "    timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
    "\n",
    "    lr_schedule = [args.train_epochs // 2 + 1]\n",
    "\n",
    "    for e in range(args.train_epochs):\n",
    "\n",
    "        train_loss, train_acc = epoch(\"train\", dataloader=trainloader, net=teacher_net, optimizer=teacher_optim,\n",
    "                                    criterion=criterion, args=args, aug=True)\n",
    "\n",
    "        test_loss, test_acc = epoch(\"test\", dataloader=testloader, net=teacher_net, optimizer=None,\n",
    "                                    criterion=criterion, args=args, aug=False)\n",
    "\n",
    "        print(\"Itr: {}\\tEpoch: {}\\tTrain Acc: {}\\tTest Acc: {}\".format(it, e, train_acc, test_acc))\n",
    "\n",
    "        timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
    "\n",
    "        if e in lr_schedule and args.decay:\n",
    "            lr *= 0.1\n",
    "            teacher_optim = torch.optim.SGD(teacher_net.parameters(), lr=lr, momentum=args.mom, weight_decay=args.l2)\n",
    "            teacher_optim.zero_grad()\n",
    "\n",
    "    trajectories.append(timestamps)\n",
    "\n",
    "    if len(trajectories) == args.save_interval:\n",
    "        n = 0\n",
    "        while os.path.exists(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))):\n",
    "            n += 1\n",
    "        print(\"Saving {}\".format(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))))\n",
    "        torch.save(trajectories, os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n)))\n",
    "        trajectories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0be55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
